{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "! Este cuadernillo no se puede ejecutar, prueba el c√≥digo en un.py\n",
    "\n",
    "# **Human-in-the-Loop en AutoGen**\n",
    "\n",
    "El enfoque **Human-in-the-Loop** (HITL) en AutoGen permite la interacci√≥n directa entre un usuario humano y un equipo de agentes en tiempo real. Esto es √∫til para: \n",
    "\n",
    "‚úÖ **Dar feedback en tiempo real** mientras el equipo est√° en ejecuci√≥n.  \n",
    "‚úÖ **Modificar la conversaci√≥n antes de continuar** en una nueva ejecuci√≥n.  \n",
    "‚úÖ **Combinar IA y supervisi√≥n humana** para mejorar respuestas.\n",
    "\n",
    "---\n",
    "\n",
    "EJEMPLO EN hip.py\n",
    "\n",
    "## **1Ô∏è‚É£ M√©todos para Proporcionar Feedback**\n",
    "\n",
    "Existen **dos formas principales** de interactuar con un equipo de agentes y proporcionar feedback:\n",
    "\n",
    "|**M√©todo**|**Descripci√≥n**|**Uso recomendado**|\n",
    "|---|---|---|\n",
    "|**Durante la ejecuci√≥n**|Se usa un `UserProxyAgent` para que el usuario pueda intervenir en tiempo real.|Para interacciones **inmediatas** (aprobaciones, selecciones r√°pidas).|\n",
    "|**Despu√©s de la ejecuci√≥n**|Se proporciona feedback en la siguiente llamada a `run()`.|Para ajustes en una **sesi√≥n persistente**.|\n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Proporcionar Feedback Durante una Ejecuci√≥n**\n",
    "\n",
    "Se usa el **`UserProxyAgent`**, un agente especial que act√∫a como **intermediario entre el usuario y el equipo**.\n",
    "\n",
    "üìå **¬øC√≥mo funciona?**\n",
    "\n",
    "1. El equipo ejecuta su tarea.\n",
    "2. En cierto momento, **se detiene y espera la intervenci√≥n del usuario**.\n",
    "3. Una vez el usuario proporciona feedback, la ejecuci√≥n contin√∫a.\n",
    "\n",
    "üí° **Ejemplo: Usar `UserProxyAgent` en un equipo de RoundRobinGroupChat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "import os\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", api_key=os.environ[\"OPENAI_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write a 4-line poem about the ocean.\n",
      "---------- assistant ----------\n",
      "Waves dance under the sun's warm embrace,  \n",
      "Whispers of secrets in a vast, blue space.  \n",
      "Tides that awaken the shores with a song,  \n",
      "In the heart of the ocean, where dreams belong.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# Crear los agentes\n",
    "assistant = AssistantAgent(\"assistant\", model_client=model_client)\n",
    "\n",
    "# Agente que permite intervenci√≥n humana a trav√©s de input()\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)\n",
    "\n",
    "# Condici√≥n de terminaci√≥n: el equipo se detendr√° si el usuario dice \"APPROVE\"\n",
    "termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Crear el equipo con el asistente y el usuario proxy\n",
    "team = RoundRobinGroupChat([assistant, user_proxy], termination_condition=termination)\n",
    "\n",
    "# Ejecutar el equipo en streaming\n",
    "await Console(team.run_stream(task=\"Write a 4-line poem about the ocean.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3Ô∏è‚É£ Proporcionar Feedback Despu√©s de la Ejecuci√≥n**\n",
    "\n",
    "Este m√©todo se usa cuando el usuario o una aplicaci√≥n deben **ajustar la tarea antes de volver a ejecutarla**.\n",
    "\n",
    "üìå **¬øC√≥mo funciona?**\n",
    "\n",
    "1. El equipo ejecuta su tarea y **se detiene**.\n",
    "2. El usuario revisa los resultados y proporciona **nuevas instrucciones**.\n",
    "3. El equipo **se reanuda con la nueva entrada**.\n",
    "\n",
    "üí° **Ejemplo: Usar `max_turns` para forzar una pausa tras cada respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Crear los agentes\n",
    "assistant = AssistantAgent(\"assistant\", model_client=model_client)\n",
    "\n",
    "# Crear el equipo con un l√≠mite de 1 turno por ejecuci√≥n\n",
    "team = RoundRobinGroupChat([assistant], max_turns=1)\n",
    "\n",
    "task = \"Write a 4-line poem about the ocean.\"\n",
    "\n",
    "while True:\n",
    "    # Ejecutar la conversaci√≥n\n",
    "    await Console(team.run_stream(task=task))\n",
    "    \n",
    "    # Pedir feedback al usuario\n",
    "    task = input(\"Enter your feedback (type 'exit' to leave): \")\n",
    "    \n",
    "    # Salir del bucle si el usuario lo decide\n",
    "    if task.lower().strip() == \"exit\":\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4Ô∏è‚É£ Uso de HandoffTermination**\n",
    "\n",
    "Algunas tareas requieren que el agente **transfiera la ejecuci√≥n al usuario** cuando no puede completar la tarea.\n",
    "\n",
    "üí° **Ejemplo: Agente que transfiere la tarea al usuario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What is the weather in New York?\n",
      "---------- lazy_assistant ----------\n",
      "[FunctionCall(id='call_XtLGpV0vQTJbvhR7DYbrraSh', arguments='{}', name='transfer_to_user')]\n",
      "---------- lazy_assistant ----------\n",
      "[FunctionExecutionResult(content='Transfer to user.', call_id='call_XtLGpV0vQTJbvhR7DYbrraSh')]\n",
      "---------- lazy_assistant ----------\n",
      "Transfer to user.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='What is the weather in New York?', type='TextMessage'), ToolCallRequestEvent(source='lazy_assistant', models_usage=RequestUsage(prompt_tokens=66, completion_tokens=12), content=[FunctionCall(id='call_XtLGpV0vQTJbvhR7DYbrraSh', arguments='{}', name='transfer_to_user')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='lazy_assistant', models_usage=None, content=[FunctionExecutionResult(content='Transfer to user.', call_id='call_XtLGpV0vQTJbvhR7DYbrraSh')], type='ToolCallExecutionEvent'), HandoffMessage(source='lazy_assistant', models_usage=None, target='user', content='Transfer to user.', context=[], type='HandoffMessage')], stop_reason='Handoff to user from lazy_assistant detected.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.base import Handoff\n",
    "from autogen_agentchat.conditions import HandoffTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Crear cliente del modelo\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n",
    "\n",
    "# Agente que transfiere la tarea al usuario si no puede responder\n",
    "lazy_agent = AssistantAgent(\n",
    "    \"lazy_assistant\",\n",
    "    model_client=model_client,\n",
    "    handoffs=[Handoff(target=\"user\", message=\"Transfer to user.\")],\n",
    "    system_message=\"If you cannot complete the task, transfer to user. Otherwise, respond with 'TERMINATE'.\",\n",
    ")\n",
    "\n",
    "# Definir condiciones de terminaci√≥n\n",
    "handoff_termination = HandoffTermination(target=\"user\")\n",
    "text_termination = TextMentionTermination(\"TERMINATE\")\n",
    "\n",
    "# Crear el equipo con ambas condiciones\n",
    "lazy_agent_team = RoundRobinGroupChat([lazy_agent], termination_condition=handoff_termination | text_termination)\n",
    "\n",
    "# Ejecutar el equipo\n",
    "await Console(lazy_agent_team.run_stream(task=\"What is the weather in New York?\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

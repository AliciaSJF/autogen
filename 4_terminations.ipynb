{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Condiciones de Terminación en AutoGen**\n",
    "\n",
    "En la sección anterior vimos cómo definir agentes y organizarlos en equipos para resolver tareas. Sin embargo, una ejecución puede continuar indefinidamente si no se le indica cuándo detenerse. Para esto, **AutoGen proporciona condiciones de terminación (termination conditions)**, que nos permiten definir criterios para detener una ejecución de manera automática.\n",
    "\n",
    "## **🔹 ¿Qué es una condición de terminación?**\n",
    "\n",
    "Una **condición de terminación** es una función que recibe una secuencia de mensajes (`AgentEvent` o `ChatMessage`) y decide si el equipo debe detenerse o continuar.  \n",
    "Si se cumple la condición, devuelve un **`StopMessage`**. Si no, devuelve `None`.\n",
    "\n",
    "📌 **Características clave**:\n",
    "\n",
    "- Son **estado-dependientes**, pero **se reinician automáticamente** después de cada ejecución (`run()` o `run_stream()`).\n",
    "- Se pueden **combinar** usando los operadores `AND (&)` y `OR (|)`.\n",
    "- En **equipos multiagente**, la condición se evalúa **después de cada respuesta de un agente**\n",
    "\n",
    "---\n",
    "## **Tipos de Condiciones de Terminación**\n",
    "\n",
    "AutoGen proporciona varias condiciones de terminación predefinidas. Aquí tienes un resumen:\n",
    "\n",
    "|**Condición**|**Descripción**|\n",
    "|---|---|\n",
    "|**MaxMessageTermination**|Detiene la ejecución cuando se alcanza un número máximo de mensajes.|\n",
    "|**TextMentionTermination**|Detiene la ejecución cuando se menciona una palabra específica (ejemplo: `\"TERMINATE\"`).|\n",
    "|**TokenUsageTermination**|Detiene la ejecución cuando se usa un cierto número de tokens.|\n",
    "|**TimeoutTermination**|Detiene la ejecución después de un tiempo límite en segundos.|\n",
    "|**HandoffTermination**|Se detiene cuando un agente transfiere el control a otro (ejemplo: usuario humano).|\n",
    "|**SourceMatchTermination**|Se detiene cuando un agente específico responde.|\n",
    "|**ExternalTermination**|Permite detener la ejecución desde fuera del equipo (por ejemplo, desde una UI).|\n",
    "|**StopMessageTermination**|Se detiene cuando un agente produce un `StopMessage`.|\n",
    "\n",
    "---\n",
    "\n",
    "## **🔹 Ejemplo 1: Uso de `MaxMessageTermination`**\n",
    "\n",
    "Creamos un equipo con un **asistente principal (`primary_agent`)** que genera contenido y un **crítico (`critic_agent`)** que da feedback.  \n",
    "Se detendrá después de **3 mensajes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_reason='stop' content='The capital of France is Paris.' usage=RequestUsage(prompt_tokens=15, completion_tokens=7) cached=False logprobs=None thought=None\n"
     ]
    }
   ],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_core.models import UserMessage\n",
    "import os\n",
    "\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment= \"gpt-4o-mini\", \n",
    "    model=\"gpt-4o-mini\",  \n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    \n",
    "\n",
    ")\n",
    "\n",
    "result = await model_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Escribe un haiku sobre el clima en París.\n",
      "---------- primary ----------\n",
      "Nubes susurran,  \n",
      "lluvia danza en el suelo,  \n",
      "París se abraza.\n",
      "---------- critic ----------\n",
      "¡Excelente haiku! Capturas muy bien la atmósfera de París con la imagen de las nubes y la lluvia. La personificación de la lluvia como una danza es especialmente evocadora. Para que el haiku se sienta aún más completo, podrías considerar incluir un elemento que conecte aún más con el ambiente urbano de la ciudad, como un monumento o una actividad cotidiana. Pero en general, es una hermosa representación del clima y la esencia de París. ¡Buen trabajo!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Escribe un haiku sobre el clima en París.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=30, completion_tokens=22), content='Nubes susurran,  \\nlluvia danza en el suelo,  \\nParís se abraza.', type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=55, completion_tokens=100), content='¡Excelente haiku! Capturas muy bien la atmósfera de París con la imagen de las nubes y la lluvia. La personificación de la lluvia como una danza es especialmente evocadora. Para que el haiku se sienta aún más completo, podrías considerar incluir un elemento que conecte aún más con el ambiente urbano de la ciudad, como un monumento o una actividad cotidiana. Pero en general, es una hermosa representación del clima y la esencia de París. ¡Buen trabajo!', type='TextMessage')], stop_reason='Maximum number of messages 3 reached, current message count: 3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "import os\n",
    "\n",
    "\n",
    "# Agente principal (genera contenido)\n",
    "primary_agent = AssistantAgent(\"primary\", model_client=model_client, system_message=\"You are a helpful AI assistant.\")\n",
    "\n",
    "# Agente crítico (da feedback)\n",
    "critic_agent = AssistantAgent(\"critic\", model_client=model_client, system_message=\"Provide constructive feedback.\")\n",
    "\n",
    "# Condición de terminación: máximo 3 mensajes\n",
    "max_msg_termination = MaxMessageTermination(max_messages=3)\n",
    "\n",
    "# Crear el equipo\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=max_msg_termination)\n",
    "\n",
    "# Ejecutar el equipo\n",
    "\n",
    "await (Console(team.run_stream(task=\"Escribe un haiku sobre el clima en París.\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔹 Ejemplo 2: Uso de `TextMentionTermination`**\n",
    "\n",
    "En este caso, la conversación **se detiene cuando el crítico responde con `\"APPROVE\"`**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Escribe un haiku sobre el clima en París.\n",
      "---------- primary ----------\n",
      "Nubes danzan hoy,  \n",
      "la brisa suave acaricia,  \n",
      "París susurra.\n",
      "---------- critic ----------\n",
      "APPROVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Escribe un haiku sobre el clima en París.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=30, completion_tokens=20), content='Nubes danzan hoy,  \\nla brisa suave acaricia,  \\nParís susurra.', type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=70, completion_tokens=3), content='APPROVE', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "import os\n",
    "\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment= \"gpt-4o-mini\", \n",
    "    model=\"gpt-4o-mini\",  \n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    ")\n",
    "\n",
    "# Agente principal (genera contenido)\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\"\n",
    ")\n",
    "\n",
    "# Agente crítico (da feedback y aprueba)\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Provide constructive feedback. If the haiku follows the correct structure, respond ONLY with 'APPROVE'.\"\n",
    ")\n",
    "\n",
    "# Condición de terminación: detener cuando el crítico mencione \"APPROVE\"\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Crear el equipo\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=text_termination)\n",
    "\n",
    "# Ejecutar el equipo\n",
    "\n",
    "await (Console(team.run_stream(task=\"Escribe un haiku sobre el clima en París.\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔹 Ejemplo 3: Combinar múltiples condiciones**\n",
    "\n",
    "Podemos **combinar condiciones** con los operadores **AND (`&`)** y **OR (`|`)**:\n",
    "\n",
    "|**Operador**|**Significado**|\n",
    "|---|---|\n",
    "|`cond1|cond2`|\n",
    "|`cond1 & cond2`|**Se detiene solo si ambas condiciones se cumplen** (AND).|\n",
    "\n",
    "💡 **Ejemplo: Detener si se alcanzan 10 mensajes o si el crítico aprueba**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Escribe un haiku sobre el clima en París.\n",
      "---------- primary ----------\n",
      "Lluvia en el aire,  \n",
      "el río canta y brilla,  \n",
      "París se despide.\n",
      "---------- critic ----------\n",
      "APPROVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Escribe un haiku sobre el clima en París.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=72, completion_tokens=22), content='Lluvia en el aire,  \\nel río canta y brilla,  \\nParís se despide.', type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=123, completion_tokens=3), content='APPROVE', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "\n",
    "# Combinar condiciones con OR (|) → Se detiene si se cumple alguna\n",
    "combined_termination = MaxMessageTermination(max_messages=10) | TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Crear el equipo con la condición combinada\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=combined_termination)\n",
    "\n",
    "# Ejecutar el equipo\n",
    "await (Console(team.run_stream(task=\"Escribe un haiku sobre el clima en París.\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔹 Ejemplo 4: Detener la ejecución desde el exterior (`ExternalTermination`)**\n",
    "\n",
    "A veces queremos **detener manualmente** el equipo (por ejemplo, en una UI con un botón \"STOP\").  \n",
    "Para esto, usamos `ExternalTermination`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 35\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\runners.py:191\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[1;32m---> 38\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py:667\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    669\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[0;32m    670\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py:626\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m--> 626\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.conditions import ExternalTermination\n",
    "\n",
    "# Crear una condición de terminación externa\n",
    "external_termination = ExternalTermination()\n",
    "\n",
    "# Crear el equipo con la condición externa\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=external_termination)\n",
    "\n",
    "# Iniciar la ejecución en segundo plano\n",
    "import asyncio\n",
    "task = asyncio.create_task(Console(team.run_stream(task=\"Escribe un poema corto.\")))\n",
    "\n",
    "# Simular una pausa y detener manualmente la ejecución\n",
    "import time\n",
    "time.sleep(5)\n",
    "external_termination.set()  # 🔴 DETENER EJECUCIÓN\n",
    "\n",
    "# Esperar a que termine la tarea\n",
    "await(task)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

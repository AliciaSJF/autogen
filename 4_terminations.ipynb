{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Condiciones de Terminaci√≥n en AutoGen**\n",
    "\n",
    "En la secci√≥n anterior vimos c√≥mo definir agentes y organizarlos en equipos para resolver tareas. Sin embargo, una ejecuci√≥n puede continuar indefinidamente si no se le indica cu√°ndo detenerse. Para esto, **AutoGen proporciona condiciones de terminaci√≥n (termination conditions)**, que nos permiten definir criterios para detener una ejecuci√≥n de manera autom√°tica.\n",
    "\n",
    "## **üîπ ¬øQu√© es una condici√≥n de terminaci√≥n?**\n",
    "\n",
    "Una **condici√≥n de terminaci√≥n** es una funci√≥n que recibe una secuencia de mensajes (`AgentEvent` o `ChatMessage`) y decide si el equipo debe detenerse o continuar.  \n",
    "Si se cumple la condici√≥n, devuelve un **`StopMessage`**. Si no, devuelve `None`.\n",
    "\n",
    "üìå **Caracter√≠sticas clave**:\n",
    "\n",
    "- Son **estado-dependientes**, pero **se reinician autom√°ticamente** despu√©s de cada ejecuci√≥n (`run()` o `run_stream()`).\n",
    "- Se pueden **combinar** usando los operadores `AND (&)` y `OR (|)`.\n",
    "- En **equipos multiagente**, la condici√≥n se eval√∫a **despu√©s de cada respuesta de un agente**\n",
    "\n",
    "---\n",
    "## **Tipos de Condiciones de Terminaci√≥n**\n",
    "\n",
    "AutoGen proporciona varias condiciones de terminaci√≥n predefinidas. Aqu√≠ tienes un resumen:\n",
    "\n",
    "|**Condici√≥n**|**Descripci√≥n**|\n",
    "|---|---|\n",
    "|**MaxMessageTermination**|Detiene la ejecuci√≥n cuando se alcanza un n√∫mero m√°ximo de mensajes.|\n",
    "|**TextMentionTermination**|Detiene la ejecuci√≥n cuando se menciona una palabra espec√≠fica (ejemplo: `\"TERMINATE\"`).|\n",
    "|**TokenUsageTermination**|Detiene la ejecuci√≥n cuando se usa un cierto n√∫mero de tokens.|\n",
    "|**TimeoutTermination**|Detiene la ejecuci√≥n despu√©s de un tiempo l√≠mite en segundos.|\n",
    "|**HandoffTermination**|Se detiene cuando un agente transfiere el control a otro (ejemplo: usuario humano).|\n",
    "|**SourceMatchTermination**|Se detiene cuando un agente espec√≠fico responde.|\n",
    "|**ExternalTermination**|Permite detener la ejecuci√≥n desde fuera del equipo (por ejemplo, desde una UI).|\n",
    "|**StopMessageTermination**|Se detiene cuando un agente produce un `StopMessage`.|\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Ejemplo 1: Uso de `MaxMessageTermination`**\n",
    "\n",
    "Creamos un equipo con un **asistente principal (`primary_agent`)** que genera contenido y un **cr√≠tico (`critic_agent`)** que da feedback.  \n",
    "Se detendr√° despu√©s de **3 mensajes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_reason='stop' content='The capital of France is Paris.' usage=RequestUsage(prompt_tokens=15, completion_tokens=7) cached=False logprobs=None thought=None\n"
     ]
    }
   ],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_core.models import UserMessage\n",
    "import os\n",
    "\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment= \"gpt-4o-mini\", \n",
    "    model=\"gpt-4o-mini\",  \n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    \n",
    "\n",
    ")\n",
    "\n",
    "result = await model_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Escribe un haiku sobre el clima en Par√≠s.\n",
      "---------- primary ----------\n",
      "Nubes susurran,  \n",
      "lluvia danza en el suelo,  \n",
      "Par√≠s se abraza.\n",
      "---------- critic ----------\n",
      "¬°Excelente haiku! Capturas muy bien la atm√≥sfera de Par√≠s con la imagen de las nubes y la lluvia. La personificaci√≥n de la lluvia como una danza es especialmente evocadora. Para que el haiku se sienta a√∫n m√°s completo, podr√≠as considerar incluir un elemento que conecte a√∫n m√°s con el ambiente urbano de la ciudad, como un monumento o una actividad cotidiana. Pero en general, es una hermosa representaci√≥n del clima y la esencia de Par√≠s. ¬°Buen trabajo!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Escribe un haiku sobre el clima en Par√≠s.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=30, completion_tokens=22), content='Nubes susurran,  \\nlluvia danza en el suelo,  \\nPar√≠s se abraza.', type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=55, completion_tokens=100), content='¬°Excelente haiku! Capturas muy bien la atm√≥sfera de Par√≠s con la imagen de las nubes y la lluvia. La personificaci√≥n de la lluvia como una danza es especialmente evocadora. Para que el haiku se sienta a√∫n m√°s completo, podr√≠as considerar incluir un elemento que conecte a√∫n m√°s con el ambiente urbano de la ciudad, como un monumento o una actividad cotidiana. Pero en general, es una hermosa representaci√≥n del clima y la esencia de Par√≠s. ¬°Buen trabajo!', type='TextMessage')], stop_reason='Maximum number of messages 3 reached, current message count: 3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "import os\n",
    "\n",
    "\n",
    "# Agente principal (genera contenido)\n",
    "primary_agent = AssistantAgent(\"primary\", model_client=model_client, system_message=\"You are a helpful AI assistant.\")\n",
    "\n",
    "# Agente cr√≠tico (da feedback)\n",
    "critic_agent = AssistantAgent(\"critic\", model_client=model_client, system_message=\"Provide constructive feedback.\")\n",
    "\n",
    "# Condici√≥n de terminaci√≥n: m√°ximo 3 mensajes\n",
    "max_msg_termination = MaxMessageTermination(max_messages=3)\n",
    "\n",
    "# Crear el equipo\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=max_msg_termination)\n",
    "\n",
    "# Ejecutar el equipo\n",
    "\n",
    "await (Console(team.run_stream(task=\"Escribe un haiku sobre el clima en Par√≠s.\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üîπ Ejemplo 2: Uso de `TextMentionTermination`**\n",
    "\n",
    "En este caso, la conversaci√≥n **se detiene cuando el cr√≠tico responde con `\"APPROVE\"`**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Escribe un haiku sobre el clima en Par√≠s.\n",
      "---------- primary ----------\n",
      "Nubes danzan hoy,  \n",
      "la brisa suave acaricia,  \n",
      "Par√≠s susurra.\n",
      "---------- critic ----------\n",
      "APPROVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Escribe un haiku sobre el clima en Par√≠s.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=30, completion_tokens=20), content='Nubes danzan hoy,  \\nla brisa suave acaricia,  \\nPar√≠s susurra.', type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=70, completion_tokens=3), content='APPROVE', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "import os\n",
    "\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment= \"gpt-4o-mini\", \n",
    "    model=\"gpt-4o-mini\",  \n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    ")\n",
    "\n",
    "# Agente principal (genera contenido)\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\"\n",
    ")\n",
    "\n",
    "# Agente cr√≠tico (da feedback y aprueba)\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Provide constructive feedback. If the haiku follows the correct structure, respond ONLY with 'APPROVE'.\"\n",
    ")\n",
    "\n",
    "# Condici√≥n de terminaci√≥n: detener cuando el cr√≠tico mencione \"APPROVE\"\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Crear el equipo\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=text_termination)\n",
    "\n",
    "# Ejecutar el equipo\n",
    "\n",
    "await (Console(team.run_stream(task=\"Escribe un haiku sobre el clima en Par√≠s.\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üîπ Ejemplo 3: Combinar m√∫ltiples condiciones**\n",
    "\n",
    "Podemos **combinar condiciones** con los operadores **AND (`&`)** y **OR (`|`)**:\n",
    "\n",
    "|**Operador**|**Significado**|\n",
    "|---|---|\n",
    "|`cond1|cond2`|\n",
    "|`cond1 & cond2`|**Se detiene solo si ambas condiciones se cumplen** (AND).|\n",
    "\n",
    "üí° **Ejemplo: Detener si se alcanzan 10 mensajes o si el cr√≠tico aprueba**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Escribe un haiku sobre el clima en Par√≠s.\n",
      "---------- primary ----------\n",
      "Lluvia en el aire,  \n",
      "el r√≠o canta y brilla,  \n",
      "Par√≠s se despide.\n",
      "---------- critic ----------\n",
      "APPROVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Escribe un haiku sobre el clima en Par√≠s.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=72, completion_tokens=22), content='Lluvia en el aire,  \\nel r√≠o canta y brilla,  \\nPar√≠s se despide.', type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=123, completion_tokens=3), content='APPROVE', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "\n",
    "# Combinar condiciones con OR (|) ‚Üí Se detiene si se cumple alguna\n",
    "combined_termination = MaxMessageTermination(max_messages=10) | TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Crear el equipo con la condici√≥n combinada\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=combined_termination)\n",
    "\n",
    "# Ejecutar el equipo\n",
    "await (Console(team.run_stream(task=\"Escribe un haiku sobre el clima en Par√≠s.\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üîπ Ejemplo 4: Detener la ejecuci√≥n desde el exterior (`ExternalTermination`)**\n",
    "\n",
    "A veces queremos **detener manualmente** el equipo (por ejemplo, en una UI con un bot√≥n \"STOP\").  \n",
    "Para esto, usamos `ExternalTermination`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 35\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\runners.py:191\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[1;32m---> 38\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py:667\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    669\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[0;32m    670\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py:626\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m--> 626\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.conditions import ExternalTermination\n",
    "\n",
    "# Crear una condici√≥n de terminaci√≥n externa\n",
    "external_termination = ExternalTermination()\n",
    "\n",
    "# Crear el equipo con la condici√≥n externa\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=external_termination)\n",
    "\n",
    "# Iniciar la ejecuci√≥n en segundo plano\n",
    "import asyncio\n",
    "task = asyncio.create_task(Console(team.run_stream(task=\"Escribe un poema corto.\")))\n",
    "\n",
    "# Simular una pausa y detener manualmente la ejecuci√≥n\n",
    "import time\n",
    "time.sleep(5)\n",
    "external_termination.set()  # üî¥ DETENER EJECUCI√ìN\n",
    "\n",
    "# Esperar a que termine la tarea\n",
    "await(task)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
